\part{Optimising approximate counterdiabatic driving}

\chapter{Counterdiabatic optimised local driving}\label{chap:4_COLD}

\epigraph{I feel a needâ€¦ a need for speed.}{LT Pete "Maverick" Mitchell, \emph{Top Gun, 1986}}

In Ch.~\ref{chap:2_adiabaticity} we established that adiabatic evolution of a quantum system requires very long timescales, without which it experiences non-adiabatic excitations out of its instantaneous eigenstate(s). This presents a problem, as the results of adiabatic dynamics - \@i.e.~keeping the system in its instantaneous eigenstate throughout evolution - are useful in many applications of quantum technologies \cite{dimitrova_many-body_2023, campo_more_2014, ebadi_quantum_2022}, but the timescales they require are often difficult to achieve due to decoherence and many other physical constraints \reminder{do I need to list anything here? + do I need more justification for wanting to achieve adiabatic dynamics?}. 

The dual motivation of implementing adiabatic evolution and doing so \emph{fast} has led to the development of a number of methods and approaches under the umbrella of shortcuts to adiabaticity (\acrref{STA})\cite{guery-odelin_shortcuts_2019}, with a universal \acrref{STA} approach being provided by counterdiabatic driving (\acrref{CD}) \cite{berry_transitionless_2009, demirplak_adiabatic_2003}, introduced in detail in Sec.~\ref{sec:2.3_CD}. However, as established in Sec.~\ref{sec:2.3_CD}, exact \acrref{CD} is often difficult to derive and even more difficult to implement in an experimental setting, leading to the development of approximate methods such as local counterdiabatic driving \cite{sels_minimizing_2017} (\acrref{LCD}) and the nested-commutator approach \cite{claeys_floquet-engineering_2019} which were already discussed in detail in Sec.~\ref{sec:2.4.1_LCD} and Sec.~\ref{sec:2.4.2_nested_commutators} respectively. Apart from the already mentioned techniques, many other approaches \cite{saberi_adiabatic_2014, campbell_shortcut_2015, whitty_quantum_2020} have been developed which aim to bypass the inherent complexity of the exact \acrref{CD}. These approximate methods all have their advantages and drawbacks when applied to particular adiabatic processes, owing both to their approximate nature and the practical aspects of their implementation.  

In this chapter I will present a new method for speeding up adiabatic processes: Counterdiabatic Optimised Local Driving (\acrref{COLD}), which was first developed with the goal of improving upon the results of \acrref{LCD} while retaining the advantages that it offers. Namely: \acrref{COLD} is a method that, given a time-dependent Hamiltonian and a set of physical constraints for the system that is being driven, can be used to construct an approximate counterdiabatic protocol that performs optimally for the given set of constraints on the Hamiltonian and the system. It does this by combining \acrref{LCD} and optimal control, which we explored in detail in Ch.~\ref{chap:3_Quantum_Optimal_control}. While \acrref{LCD} can be used to implement an approximate \acrref{CD} protocol built out of restricted, physically realisable operators, \acrref{COLD} does this while finding an optimal path for the system, such that the approximate counterdiabatic drive is maximally effective in suppressing non-adiabatic effects.

I will begin the chapter by introducing the \acrref{COLD} method in detail,\reminder{finish this}

\section{Counterdiabatic driving and optimal control}

Let us begin by explicitly setting the stage for the problem that we want to solve. Given a Hamiltonian $H(\lambda)$, which depends on time via the parameter $\lambda(t)$, and a system prepared in an eigenstate of $H(\lambda_0)$, where $\lambda_0 = \lambda(0)$ (often this is the ground state, but it need not be), our task is to vary the parameter $\lambda$ from its initial value $\lambda_0$ to some final value $\lambda_f = \lambda(\tau)$ during a duration of time $\tau$ such that at the end of the process, the system is in the corresponding eigenstate of $H(\lambda_f)$. More precisely, if \@e.g.~the system starts in the ground state of $H(\lambda_0)$, after the evolution it should be in the ground state of $H(\lambda_f)$. This can be done quite reliably, as per the discussion of Ch.\ref{chap:2_adiabaticity}, as long as the instantaneous eigenstates of the Hamiltonian driving the system are degenerate throughout the evolution and the driving happens slowly enough (see Sec.~\ref{sec:2.1.2_adiabatic_condition}). However, bearing in mind that such slow evolution is generally not accessible, our primary goal is to achieve this result while keeping $\tau$ small \@i.e.~making the evolution as fast as possible. 

As already mentioned in the introduction to this Chapter, one way to achieve this task is by using \acrref{CD} (Sec.~\ref{sec:2.3_CD}). That is, for a given $H(\lambda)$, it may be possible to derive and implement an exact counterdiabatic Hamiltonian from Eq.~\ref{eq:CD_Hamiltonian} which suppresses all non-adiabatic effects experienced by the system due to fast driving. Exact \acrref{CD} could, in this way, keep a system in the instantaneous eigenstate of $H(\lambda)$ during arbitrarily short driving times (within the geometric speed limit \cite{bukov_geometric_2019}), but exact \acrref{CD} is a commodity that is not generally accessible for an arbitrary Hamiltonian \cite{kolodrubetz_geometry_2017}, much less implementable in practice, as it often requires highly non-local operators. 

The next best thing to try, then, might be an approximate \acrref{CD} method like \acrref{LCD}. As discussed in Sec.~\ref{sec:2.4.1_LCD}, \acrref{LCD} not only allows one to approximate the full \acrref{CD}, thus suppressing some of the losses associated with non-adiabatic effects, but it also gives one the freedom to choose the basis of operators for the approximation, making it very attractive in experimental settings where only a limited set of physical operators are available. If an ansatz is not forthcoming, it is also possible to use the ideas presented in Sec.~\ref{sec:2.4.2_nested_commutators} to build up a local operator basis which contributes to the full \acrref{CD} via the nested commutator approach \cite{geier_floquet_2021} and to then use the variational method of \acrref{LCD} in order to construct a counterdiabatic schedule made up of a physically implementable subset of that basis. 

The \acrref{LCD} method is powerful, but it is not without its faults. The primary disadvantage of such an approach is that the counterdiabatic drive being implemented will always be an \emph{approximation} unless the ansatz basis is fully representative of the exact \acrref{CD}. In cases where the approximation is a poor one, the \acrref{LCD} technique might not offer much suppression of errors at all. One solution to this would simply be to expand the ansatz basis in order to access more degrees of freedom in describing the \acrref{CD}, but this would be counter to the idea of only requiring a physically implementable set of operators as part of the approximation in order to make it useful in an experimental setting. The other would be to use a different method entirely to achieve the same result by, for example, taking a page out of optimal control theory as covered extensively in Ch.~\ref{chap:3_Quantum_Optimal_control}. It is not obvious, however, that a switch in tactics would lead to an improvement or what the complexity of designing a new approach might be. This leaves us at a bit of an impasse: unless there is a better, physically realisable driving schedule than the \acrref{LCD} for a given ansatz set of operators, then there may be no other way to drive a system quickly while suppressing more losses.

This is where we come to the new method, \acrref{COLD}, which was developed with the aim of retaining the advantages of \acrref{LCD} while improving upon its results. The approach begins with the observation that any counterdiabatic schedule will depend on the driving path of the original Hamiltonian for which it is constructed, as discussed extensively in Ch.~\ref{chap:2_adiabaticity}. Namely, if we write a time-dependent Hamiltonian $H$ as a sum of $N_H$ operators $\{ \mathcal{O}_H^{(i)} \}_{i = 1,...,N_H}$ each scaled by a time-dependent coefficient $h_i(\lambda) \in \hbb$:
\begin{equation}
    H(\lambda, \hbb) = \sum_{i = 1}^{N_H} h_i(\lambda) \mathcal{O}_H^{(i)},
\end{equation}
then the \acrref{CD} drive can be expressed as a sum of operators $\{\mathcal{O}_{CD}^{(j)}\}_{j = 1,...,N_{\rm CD}}$ which are scaled by functions $\alpha_{j}(\lambda, \hbb, \dot{\hbb})$ and the rate of change in the parameters $\dotlambda$. That is to say the form of the counterdiabatic drive is a function of the time-dependent parameter $\lambda$ and the coefficients of the operators making up $H(\lambda)$ as well as their derivatives. Looking back at Eq.~\eqref{eq:CD_Hamiltonian}, we can now write the counterdiabatic Hamiltonian as:
\begin{equation}
    \begin{aligned}
        H_{\rm CD} &= H(\lambda, \hbb) + \dotlambda \AGP{\lambda} \\
        &= \sum_{i = 1}^{N_H} h_i(\lambda) \mathcal{O}_H^{(i)} + \sum_{j = 1}^{N_{\rm CD}} \dotlambda \alpha_{j}(\lambda, \hbb, \dot{\hbb}) \mathcal{O}_{CD}^{(j)},
    \end{aligned}
\end{equation}
where you can now view the operators $\{\mathcal{O}_{CD}\}$ as a basis of the adiabatic gauge potential $\AGP{\lambda}$ (\acrref{AGP}) which was introduced at length in Sec.~\ref{sec:2.2_AGP}. We can even see how this relationship comes about by looking at the matrix elements of the \acrref{AGP} in Eq.~\eqref{eq:AGP_adiabatic_basis}, which are a function of the instantaneous eigenenergies of $H(\lambda, \hbb)$ and the matrix elements of $\dlambda H(\lambda, \hbb)$, all of which can be written as functons of $\lambda, \hbb$ and $\dot{\hbb}$. 

In this setting, we can view the \acrref{LCD} method as a way to variationally find the coefficients $\alpha_j$ for a given subset of $\{\mathcal{O}_{CD}\}$ which minimise the distance between the approximate operator obtained with the truncated basis $\approxAGP$ and the full \acrref{AGP}. If we start with an ansatz basis which forms the support of the full \acrref{AGP}, then the variational method can be used to find the exact counterdiabatic drive. 

The reason for expressing the counterdiabatic Hamiltonian in this way is to make the dependence of the coefficients $\alpha_j$ on the functions $\hbb$ and $\lambda$ explicit. The philosophy of \acrref{COLD} as a method begins with the observation that the form of the counterdiabatic drive will depend on the path of the Hamiltonian in the parameter space of its coefficients, \@i.e.~if we change either $\hbb$ or $\lambda$ (or both), the form of the counterdiabatic drive will change via the functions $\alpha_j$. Thus, one can imagine a scenario where 

This can be traced back to the fact that 

\begin{equation}\label{eq:expandedH}
H_{\rm COLD}(\lambda,\betabb) = H_0(\lambda) + {\boldsymbol \alpha}(\lambda,\betabb) \mathcal{O}_{\rm LCD} + \betabb(\lambda) \mathcal{O}_{\rm opt}.
\end{equation}


\section{Optimal control toolbox}

With optimal control being one of the two key components of \acrref{COLD}, I will now revisit the content covered in Ch.~\ref{chap:3_Quantum_Optimal_control}, linking it to the way one might go about constructing control pulses in this new, counterdiabatic setting. In Sec.~\ref{sec:3.3_qoct_methods} we covered ``Chopped Randomised Basis" (\acrref{CRAB}) and ``Gradient Ascent Pulse Engineering" (\acrref{GRAPE}), two quantum optimal control methods that offer very flexible yet powerful approaches to constructing and optimising control pulses. Consequently, we can use them in the setting of \acrref{COLD} too. In our original work presented in Ref.~\cite{cepaite_counterdiabatic_2023}, three separate techniques for constructing optimal control pulses were implemented:
\begin{itemize}
    \item `Bare' pulses, which are \acrref{CRAB}-like functions composed of a Fourier basis where each basis function is scaled by an optimisable coefficient, similar to those given by Eq.~\ref{eq:trigonometric_CRAB}. They name `bare' is used to distinguish them from \acrref{CRAB} as they do not include any randomisation component.
    \item \acrref{COLD}-\acrref{CRAB} pulses, which are like the bare version but with the inclusion of randomisation in the frequencies of the basis functions used to construct the pulse, as discussed in Sec.~\ref{sec:3.3.1_CRAB}.
    \item \acrref{COLD}-\acrref{GRAPE} pulses, wherein the optimisable function is constructed using the \acrref{GRAPE} approach of parameterised piecewise constant time slices, as was expanded upon in detail in Sec.~\ref{sec:3.3.2_GRAPE}. 
\end{itemize}

These three techniques will be discussed in more detail in the rest of this section, along with 


\subsection{Bare pulses}

\subsection{COLD-CRAB}

While the ``Chopped Randomised Basis" (\acrref{CRAB}) algorithm,


\subsection{COLD-GRAPE}

Modified version of \acrref{GRAPE}: not the gradient-based approach, but rather one which 

spline, interpolation

\subsection{Optimisation constraints}

In the case of all of the above methods, it 

\subsection{Other combinations of QOCT and CD}

I want to finish this chapter with a summary of the 