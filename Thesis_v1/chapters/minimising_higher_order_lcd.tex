\chapter{Adiabatic gauge potential as a cost function}\label{chap:5_cd_as_costfunc}

\epigraph{Always remember, however, that thereâ€™s usually a simpler and better way to do something than the first way that pops into your head.}{\emph{Donald Knuth}}

In the previous chapter we presented the \acrref{COLD} method, which combines \acrref{LCD} (Sec.~\ref{sec:2.4.1_LCD}) and quantum optimal control (Sec.~\ref{sec:3.2_Quantum_optimal_control}) in order to speed up adiabatic quantum processes while minimising transitions out of the instantaneous eigenstates. The strategy of \acrref{COLD} is largely concerned with implementing optimal control in order to modify the path of the time-dependent Hamiltonian in parameter space in a way that maximises the effectiveness of a given \acrref{LCD} drive in driving a system to a target eigenstate of the adiabatic Hamiltonian. The optimal control component of \acrref{COLD} is thus constructed around optimising for the final state of the system after evolution: whether by assessing its fidelity with respect to some target state or a property like entanglement.

In this chapter we will take a slightly different but complementary perspective on combining \acrref{LCD} and optimal control by asking the question of what happens when, instead of optimising for a particular target state, we use only information about the counterdiabatic drive - or rather, the \acrref{AGP} from Sec.~\ref{sec:2.2_AGP} - as the optimal control cost function. Since the \acrref{AGP} contains information about the non-adiabatic effects experienced by a system, it is reasonable to believe that this information can be extracted and its analysis can be useful in designing optimal fast driving schedules for adiabatic protocols. 

We will begin the chapter with a brief motivation behind using the counterdiabatic pulse as a metric for optimising fast adiabatic processes in Sec.~\ref{sec:5.1_motivation} and then in Sec.~\ref{sec:5.2_designing_costfunc_hocd} we will explore several different ways in which the \acrref{CD} pulse can be transformed into an optimal control cost function. While this chapter will introduce the theory behind the idea, Ch.~\ref{chap:7_higher_order_agp} will present the numerical simulation results obtained using the ideas in this chapter.

\section{Motivation}\label{sec:5.1_motivation}

Returning to the key ideas behind \acrref{CD}, we may recall that the exact \acrref{CD} pulse is comprised of the \acrref{AGP} (Sec.~\ref{sec:2.2_AGP}) operator $\AGP{\lambda}$ scaled by the rate of change of $\lambda(t)$ (expressed as $\dotlambda$) in the adiabatic Hamiltonian, as given by Eq.~\eqref{eq:CD_Hamiltonian}. The \acrref{AGP} is the generator of adiabatic deformations between quantum eigenstates, and its off-diagonal elements are responsible for transitions between the instantaneous (or adiabatic) eigenstates or, put another way, the Frobenius norm of the \acrref{AGP} is the distance between nearby eigenstates \cite{pandey_adiabatic_2020, nandy_delayed_2022}. Thus, there are two components comprising the non-adiabatic effects experienced by a system driven at finite time by a time-dependent Hamiltonian: the rate of change of the parameters $\dotlambda$ and the \acrref{AGP} operator, which can be quantified \@e.g.~via its norm. 

In the design fast adiabatic protocols such as the techniques under the umbrella of \acrref{STA}, we are competing against $\dotlambda$ as the aim in general is speed rather than adherence to the adiabatic condition. This leaves us with minimising $\AGP{\lambda}$ or else, as in the case of \acrref{CD}, suppressing or mitigating its effects. To whit, \acrref{LCD} does this by implementing an operator that approximately suppresses the \acrref{AGP} for a given Hamiltonian. \acrref{COLD} then aids in this endeavour by modifying the Hamiltonian and thus the corresponding \acrref{AGP} operator in a way that allows for a given \acrref{LCD} protocol to perform better. The optimal control component of \acrref{COLD} in \cite{cepaite_counterdiabatic_2023} and throughout Ch.~\ref{chap:6_Applications_fidelity} is implemented with the target state fidelity (Eq.~\eqref{eq:costfunc_fidelity}) as a cost function, which is down to the fact that the primary application of adiabatic protocols in often (though not always \cite{pelegri_high-fidelity_2022}) state preparation. The use of fidelity as a cost function, however, necessitates access to the wavefunction of the final state, something that becomes difficult to compute for large or highly correlated systems and may result in a highly non-convex or complex cost function landscape (see, for example, Fig.~\ref{fig:ghz_contours}). Furthermore, fidelity is not a useful cost function in practice in the case where the target state is unknown, which is common in \@e.g.~applications of adiabatic protocols to Hamiltonians whose ground states encode solutions to combinatorics problems \cite{ebadi_quantum_2022, albash_adiabatic_2018}. 

A solution to the problem of fidelity as a cost function might be the use of a different metric for optimising the Hamiltonian path. We have established that $\AGP{\lambda}$ contains information pertaining to non-adiabatic losses experienced by a driven system, thus a natural approach to optimising the path of the Hamiltonian would be to minimise the \acrref{AGP} operator (we will discuss the details of this in the next section), as this should in principle minimise losses associated with non-adiabaticity. The main advantages of such an approach would be the fact that  the minimisation should be far more efficient than any attempt to compute the full system evolution, assuming we have access to the \acrref{AGP} as a function of the Hamiltonian path in parameter space. Furthermore, this process would require no knowledge of the system wavefunction at any point, removing the drawbacks discussed earlier concerning the fidelity cost function.

\section{Designing a cost function around the counterdiabatic pulse}\label{sec:5.2_designing_costfunc_hocd}

There are several ways to define a metric on a time-dependent pulse and in this thesis we will explore two in particular. In order to do this, we will first return to Ch.~\ref{chap:4_COLD}, where we expressed the \acrref{CD} pulse as a sum of operators $\{\mathcal{O}_{\rm CD}^{(j)}\}_{j = 1, ..., N_{\rm CD}}$ which are scaled by coefficients $\alpha_j(\lambda, \hbb)$ with $\lambda$ a function of time and $\hbb$ the $\lambda$-dependent coefficients of the Hamiltonian $H(\lambda)$. In the \acrref{LCD} case, this sum is truncated to a set of operators $\{\mathcal{O}_{\rm LCD}\} \subset \{\mathcal{O}_{\rm CD}\}$ which are themselves scaled by a different set of coefficients $\alpha_j^{\prime}(\lambda, \hbb)$. Expressed this way, we can view the operators as static, with the $\lambda$- and $\hbb$-dependent coefficients $\alpha_j$ and $\alpha_j^{\prime}$ encoding the shape of the pulse and containing the information about non-adiabatic effects for given values of $\lambda$ and $\hbb$. If we include an optimal control component parameterised by functions $\beta_k(\lambda) \in \betabb$ as in Eq.~\eqref{eq:COLD_optimal_control} in the case of \acrref{COLD}, then the counterdiabatic coefficients become dependent on $\betabb$ too, allowing us to optimise them by varying the control functions.

Given this form for the counterdiabatic pulses, we can choose two types of metrics: one which looks at the whole pulse, whether in the case of the exact \acrref{AGP} or some truncation obtained using \acrref{LCD} and another which instead only picks out an extremum of the pulse, like its maximum amplitude. In the first case, a natural option would be the time-integrated absolute value of the $\alpha_j$ coefficients, which in the optimal control community is often referred to as the ``control effort"\cite{petersen_control_1987}:
\begin{equation}\label{eq:COLD_costfunc_integral}
    C_{\rm I}(\tau, \betabb) = \sum_j^{N_I} \int_{0}^{\tau} dt^{\prime} |\alpha_j^{\prime}(\lambda(t^{\prime}), \hbb, \betabb)|,
\end{equation}
where, as before, $\tau$ is the total driving time and here we take the sum over $N_I$ coefficients. When the quantity $C_I(\tau, \betabb)$ is minimised, naturally the contribution of the operators scaled by the coefficients in the sum will be reduced. When it is $0$, then these operators will not contribute at all to the non-adiabatic losses experienced by the driven system. It should be noted that understanding the physical meaning behind non-zero values of $C_I$ is quite non-trivial, although it is natural to expect that the larger it is, the more losses the system experiences. 

In the case where we want to minimise the exact \acrref{AGP}, $N_I = N_{CD}$. On the other hand, when it comes to \acrref{LCD} it may be fruitful to minimise $\alpha_j^{\prime}$ corresponding to operators which are not actually applied to the system. Say one has access to a set of operators with a non-zero contribution to the exact \acrref{CD} with the ability to implement only a subset, \@e.g.~they were obtained via the nested commutator approach from Sec.~\ref{sec:2.4.2_nested_commutators}. Then it is sensible to optimise for a path which minimises the contribution of the subset of operators that \emph{cannot} be implemented. This should theoretically reduce their contribution to the non-adiabatic losses. In this way, an \acrref{LCD} protocol can be used to both suppress non-adiabatic losses by the application of an approximate counterdiabatic drive and to optimise for a Hamiltonian path which reduces the non-suppressed losses experienced by the system.

The second option for a cost function which uses nothing but the counterdiabatic pulse coefficients is one which instead minimises some extremum of the entire pulse, such as the maximal absolute amplitude reached by the pulse throughout the evolution, which we will write as:
\begin{equation}\label{eq:COLD_costfunc_maximum}
    C_{\rm A}(\tau, \betabb) = \max_{t^{\prime} \in [0,\tau]} \left( \sum_j^{N_I} | \alpha_j(\lambda(t^{\prime}), \hbb, \betabb)|\right).
\end{equation}

Intuitively, if the integral cost function is $0$, then this second approach does not provide any more information as the two will be equivalent. However, what this cost function captures is whether or not the path of the system for a given $\betabb$ and $\tau$ experiences any critical point in its evolution where the non-adiabatic effects are maximised, for example in the case of closing gaps between the instantaneous eigenstates. This cost function may be useful in cases where one wants to avoid such closing gaps within the system evolution and no path optimally suppresses all non-adiabatic effects. In particular, it might be used in \acrref{LCD} as a means to avoid cases where the \acrref{CD} operators which are not applied are responsible for most of the avoided transitions out of the instanteous eigenstate.